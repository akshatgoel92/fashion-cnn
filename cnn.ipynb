{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow.contrib.layers as layers\n",
    "from tensorflow.examples.tutorials.mnist import input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.12.0\n"
     ]
    }
   ],
   "source": [
    "# Print version\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get data from URL endpoint\n",
    "def get_data(s3_endpoint = 'http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/'):\n",
    "    \n",
    "    data = input_data.read_data_sets('data/fashion', \n",
    "                                     source_url = s3_endpoint, \n",
    "                                     one_hot = True)\n",
    "    \n",
    "    return(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create placeholders for data\n",
    "def get_data_placeholders(batch_size):\n",
    "    \n",
    "    X = tf.placeholder(tf.float32, shape=[batch_size, 784])\n",
    "    Y = tf.placeholder(tf.float32, shape=[batch_size, 10])\n",
    "    \n",
    "    return(X,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define forward pass function\n",
    "def forward(X, arch, batch_size):\n",
    "    \n",
    "    image = tf.reshape(X, [batch_size, 28, 28, 1])\n",
    "    hidden_layer = image\n",
    "    \n",
    "    for size in arch:\n",
    "        num_filters, dim_filters, stride = size[0], size[1], size[2]\n",
    "        hidden_layer = layers.conv2d(hidden_layer, num_filters, dim_filters, stride, \"Same\")\n",
    "        convOut= tf.nn.relu(hidden_layer)\n",
    "    \n",
    "    new_shape = tf.divide(tf.size(hidden_layer), batch_size)\n",
    "    hidden_layer = tf.reshape(hidden_layer, [batch_size, new_shape])\n",
    "    prbs = layers.fully_connected(hidden_layer, 10, tf.nn.softmax)\n",
    "    \n",
    "    return(prbs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define loss function\n",
    "def get_loss(Y, probs):\n",
    "    \n",
    "    loss = tf.reduce_mean(-1*tf.reduce_sum(Y*tf.log(probs), reduction_indices=[1]))\n",
    "    \n",
    "    return(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get accuracy\n",
    "def get_accuracy(prbs, ans):\n",
    "    \n",
    "    correct = tf.equal(tf.argmax(prbs,1), tf.argmax(ans,1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))\n",
    "    \n",
    "    return(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get graph\n",
    "def get_graph(batch_size, num_epochs, arch, learning_rate):\n",
    "    \n",
    "    X, Y = get_data_placeholders(batch_size)\n",
    "    probs = forward(X, arch, batch_size)\n",
    "    loss = get_loss(Y, probs)\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(loss)\n",
    "    nodes = [X, Y, probs, loss, optimizer]\n",
    "    \n",
    "    return(nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define training method\n",
    "def train_model(batch_size, num_epochs, nn_arch, learning_rate):\n",
    "    \n",
    "    # Get nodes\n",
    "    graph_nodes = get_graph(batch_size, num_epochs, nn_arch, learning_rate)\n",
    "    \n",
    "    # Unpack\n",
    "    X = graph_nodes[0] \n",
    "    Y = graph_nodes[1] \n",
    "    \n",
    "    probs = graph_nodes[2] \n",
    "    loss = graph_nodes[3] \n",
    "    optimizer = graph_nodes[4] \n",
    "    \n",
    "    # Get accuracy graph\n",
    "    accuracy = get_accuracy(probs, Y)\n",
    "    \n",
    "    # Start session\n",
    "    sess = tf.Session()\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    # Train\n",
    "    total_acc = 0\n",
    "    \n",
    "    for i in range(num_epochs):\n",
    "        print(\"The epoch is {}\".format(i))\n",
    "        imgs, labels = train.next_batch(batch_size)\n",
    "        _, acc = sess.run([optimizer,accuracy], feed_dict={X: imgs, Y: labels})\n",
    "        total_acc +=acc\n",
    "        \n",
    "    print('The training accuracy is {}'.format(total_acc/num_epochs))\n",
    "    \n",
    "    # Get predictions on dev. set\n",
    "    total_acc = 0\n",
    "    \n",
    "    for i in range(num_epochs):\n",
    "        imgs, labels = dev.next_batch(batch_size)\n",
    "        acc = sess.run(accuracy, feed_dict={X: imgs, Y: labels})\n",
    "        total_acc += acc\n",
    "    \n",
    "    print('The dev. accuracy is {}'.format(total_acc/num_epochs))\n",
    "        \n",
    "    \n",
    "    # Get predictions on test set\n",
    "    total_acc = 0\n",
    "    \n",
    "    for i in range(num_epochs):\n",
    "        imgs, labels = test.next_batch(batch_size)\n",
    "        total_acc+=sess.run(accuracy, feed_dict={X: imgs, Y: labels})\n",
    "    \n",
    "    print('The test accuracy is {}'.format(total_acc/num_epochs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/fashion/train-images-idx3-ubyte.gz\n",
      "Extracting data/fashion/train-labels-idx1-ubyte.gz\n",
      "Extracting data/fashion/t10k-images-idx3-ubyte.gz\n",
      "Extracting data/fashion/t10k-labels-idx1-ubyte.gz\n",
      "The epoch is 0\n",
      "The epoch is 1\n",
      "The epoch is 2\n",
      "The epoch is 3\n",
      "The epoch is 4\n",
      "The epoch is 5\n",
      "The epoch is 6\n",
      "The epoch is 7\n",
      "The epoch is 8\n",
      "The epoch is 9\n",
      "The epoch is 10\n",
      "The epoch is 11\n",
      "The epoch is 12\n",
      "The epoch is 13\n",
      "The epoch is 14\n",
      "The epoch is 15\n",
      "The epoch is 16\n",
      "The epoch is 17\n",
      "The epoch is 18\n",
      "The epoch is 19\n",
      "The epoch is 20\n",
      "The epoch is 21\n",
      "The epoch is 22\n",
      "The epoch is 23\n",
      "The epoch is 24\n",
      "The epoch is 25\n",
      "The epoch is 26\n",
      "The epoch is 27\n",
      "The epoch is 28\n",
      "The epoch is 29\n",
      "The epoch is 30\n",
      "The epoch is 31\n",
      "The epoch is 32\n",
      "The epoch is 33\n",
      "The epoch is 34\n",
      "The epoch is 35\n",
      "The epoch is 36\n",
      "The epoch is 37\n",
      "The epoch is 38\n",
      "The epoch is 39\n",
      "The epoch is 40\n",
      "The epoch is 41\n",
      "The epoch is 42\n",
      "The epoch is 43\n",
      "The epoch is 44\n",
      "The epoch is 45\n",
      "The epoch is 46\n",
      "The epoch is 47\n",
      "The epoch is 48\n",
      "The epoch is 49\n",
      "The epoch is 50\n",
      "The epoch is 51\n",
      "The epoch is 52\n",
      "The epoch is 53\n",
      "The epoch is 54\n",
      "The epoch is 55\n",
      "The epoch is 56\n",
      "The epoch is 57\n",
      "The epoch is 58\n",
      "The epoch is 59\n",
      "The epoch is 60\n",
      "The epoch is 61\n",
      "The epoch is 62\n",
      "The epoch is 63\n",
      "The epoch is 64\n",
      "The epoch is 65\n",
      "The epoch is 66\n",
      "The epoch is 67\n",
      "The epoch is 68\n",
      "The epoch is 69\n",
      "The epoch is 70\n",
      "The epoch is 71\n",
      "The epoch is 72\n",
      "The epoch is 73\n",
      "The epoch is 74\n",
      "The epoch is 75\n",
      "The epoch is 76\n",
      "The epoch is 77\n",
      "The epoch is 78\n",
      "The epoch is 79\n",
      "The epoch is 80\n",
      "The epoch is 81\n",
      "The epoch is 82\n",
      "The epoch is 83\n",
      "The epoch is 84\n",
      "The epoch is 85\n",
      "The epoch is 86\n",
      "The epoch is 87\n",
      "The epoch is 88\n",
      "The epoch is 89\n",
      "The epoch is 90\n",
      "The epoch is 91\n",
      "The epoch is 92\n",
      "The epoch is 93\n",
      "The epoch is 94\n",
      "The epoch is 95\n",
      "The epoch is 96\n",
      "The epoch is 97\n",
      "The epoch is 98\n",
      "The epoch is 99\n",
      "The training accuracy is 0.11600000225007534\n",
      "The dev. accuracy is 0.10700000219047069\n",
      "The test accuracy is 0.10000000163912773\n"
     ]
    }
   ],
   "source": [
    "# Execute\n",
    "if __name__ == '__main__':\n",
    "    \n",
    "    # Set a seed to make sure results are reproducible\n",
    "    tf.set_random_seed(1234)\n",
    "\n",
    "    # Get data\n",
    "    data = get_data()\n",
    "    \n",
    "    # Get training, dev., and test sets\n",
    "    train, dev, test = data.train, data.validation, data.test\n",
    "    \n",
    "    # Set parameters\n",
    "    batch_size = 10\n",
    "    num_epochs = 100\n",
    "    nn_arch = [[32, [2,2], 1], [16, [2,2], 1], [12, [2,2], 1], [10, [2,2], 1]]\n",
    "    learning_rate = 0.2\n",
    "    \n",
    "    # Train\n",
    "    train_model(batch_size, num_epochs, nn_arch, learning_rate)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
